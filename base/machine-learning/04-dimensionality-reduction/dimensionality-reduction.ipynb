{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction\n",
    "\n",
    "We will go over a few of the main dimensionality reduction techniques in the machine learning space.\n",
    "\n",
    "### Table of Contents\n",
    "1. []()\n",
    "\n",
    "## Preliminaries\n",
    "\n",
    "Design / Data Matrix:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\underset{n\\times m}{\\mathbf{X}} &= \\underset{n\\,\\text{samples}\\,\\times \\,m\\,\\text{features}}{\\begin{bmatrix} x_{11} & x_{12} & \\ldots & x_{1m} \\\\ x_{21} & x_{22} & \\ldots & x_{2m} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ x_{n1} & x_{n2} & \\ldots & x_{nm} \\\\ \\end{bmatrix}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Unit Matrix (Matrix of all ones):\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\underset{n\\times n}{\\mathbf{e}\\mathbf{e}^\\top} &= \\begin{bmatrix} 1 \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{bmatrix} \\cdot \\begin{bmatrix} 1 & 1 & \\ldots & 1 \\end{bmatrix} \\\\\n",
    "&= \\underset{n\\,\\times \\,n}{\\begin{bmatrix} 1 & 1 & \\ldots & 1 \\\\ 1 & 1 & \\ldots & 1 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & 1 & \\ldots & 1 \\\\ \\end{bmatrix}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Matrix of Feature / Covariate Means:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\underset{n\\times m}{\\bar{\\mathbf{X}}} &= \\frac{1}{n}\\cdot\\mathbf{e}\\mathbf{e}^\\top\\cdot \\underset{n\\times m}{\\mathbf{X}} \\\\\n",
    "&= \\underset{n\\,\\text{duplicates of feature means}\\,\\times \\,m\\,\\text{features}}{\\begin{bmatrix} \\bar{x}_{1} & \\bar{x}_{2} & \\ldots & \\bar{x}_{m} \\\\ \\bar{x}_{1} & \\bar{x}_{2} & \\ldots & \\bar{x}_{m} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ \\bar{x}_{1} & \\bar{x}_{2} & \\ldots & \\bar{x}_{m} \\\\ \\end{bmatrix}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Sample Data ($\\frac{1}{n - 1}$) Covariance Matrix:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\underset{m\\times m}{\\Sigma} &= \\frac{1}{n - 1} {(\\underset{n\\times m}{\\mathbf{X}} - \\underset{n\\times m}{\\bar{\\mathbf{X}}})}^\\top \\cdot {(\\underset{n\\times m}{\\mathbf{X}} - \\underset{n\\times m}{\\bar{\\mathbf{X}}})} \\\\\n",
    "&= \\frac{1}{n - 1} \\begin{bmatrix} x_{11} - \\bar{x}_{1} & x_{21} - \\bar{x}_{1} & \\ldots & x_{n1} - \\bar{x}_{1} \\\\ x_{12} - \\bar{x}_{2} & x_{22} - \\bar{x}_{2} & \\ldots & x_{n2} - \\bar{x}_{2} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ x_{1m} - \\bar{x}_{m} & x_{2m} - \\bar{x}_{m} & \\ldots & x_{nm} - \\bar{x}_{m} \\\\ \\end{bmatrix} \\cdot \\begin{bmatrix} x_{11} - \\bar{x}_{1} & x_{12} - \\bar{x}_{2} & \\ldots & x_{1m} - \\bar{x}_{m} \\\\ x_{21} - \\bar{x}_{1} & x_{22} - \\bar{x}_{2} & \\ldots & x_{2m} - \\bar{x}_{m} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ x_{n1} - \\bar{x}_{1} & x_{n2} - \\bar{x}_{2} & \\ldots & x_{nm} - \\bar{x}_{m} \\\\ \\end{bmatrix} \\\\\n",
    "&= \\frac{1}{n - 1} \\begin{bmatrix} \n",
    "\\sum^{n}_{i = 1} {(x_{i1} - \\bar{x}_{1})}{(x_{i1} - \\bar{x}_{1})} & \\sum^{n}_{i = 1} {(x_{i1} - \\bar{x}_{1})}{(x_{i2} - \\bar{x}_{2})} & \\ldots & \\sum^{n}_{i = 1} {(x_{i1} - \\bar{x}_{1})}{(x_{im} - \\bar{x}_{m})} \\\\ \n",
    "\\sum^{n}_{i = 1} {(x_{i2} - \\bar{x}_{2})}{(x_{i1} - \\bar{x}_{1})} & \\sum^{n}_{i = 1} {(x_{i2} - \\bar{x}_{2})}{(x_{i2} - \\bar{x}_{2})} & \\ldots & \\sum^{n}_{i = 1} {(x_{i2} - \\bar{x}_{2})}{(x_{im} - \\bar{x}_{m})} \\\\ \n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\ \n",
    "\\sum^{n}_{i = 1} {(x_{im} - \\bar{x}_{m})}{(x_{i1} - \\bar{x}_{1})} & \\sum^{n}_{i = 1} {(x_{im} - \\bar{x}_{m})}{(x_{i2} - \\bar{x}_{2})} & \\ldots & \\sum^{n}_{i = 1} {(x_{im} - \\bar{x}_{m})}{(x_{im} - \\bar{x}_{m})} \\\\ \\end{bmatrix} \\\\\n",
    "&= \\begin{bmatrix} \n",
    "Var(x_1) & Cov(x_1, x_2) & \\ldots & Cov(x_1, x_m) \\\\ \n",
    "Cov(x_2, x_1) & Var(x_2) & \\ldots & Cov(x_2, x_m) \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "Cov(x_m, x_1) & Cov(x_m, x_2) & \\ldots & Var(x_m) \\\\ \n",
    "\\end{bmatrix}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Principal Component Analysis\n",
    "\n",
    "1. Compute Covariance matrix $\\Sigma$\n",
    "2. Get Singular Value Decomposition of $\\Sigma$\n",
    "3. Take the $k$-first eigenvectors of $U$ matrix, $U_k$\n",
    "4. $U_k^\\top \\cdot \\mathbf{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Factor Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Canonical Correlation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# TSNE (T-distributed Stochastic Neighbourhood Embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Resources:\n",
    "\n",
    "General:\n",
    "- [Penn State's STAT505 Lesson Notes](https://newonlinecourses.science.psu.edu/stat505/)\n",
    "\n",
    "PCA:\n",
    "- [Stat Quest's \"StatQuest: Principal Component Analysis (PCA), Step-by-Step\"](https://www.youtube.com/watch?v=FgakZw6K1QQ&t=16s)\n",
    "- [Very intuitive and detailed explanation of PCA](https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues)\n",
    "- [Andrew Ng on PCA](https://www.youtube.com/watch?v=rng04VJxUt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
