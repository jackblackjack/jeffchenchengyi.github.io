{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling with Trees\n",
    "\n",
    "We will go through an overview of the different types of tree-based algorithms in the literature and how they work using ensembling techniques like bagging (boostrapping + aggregating) and boosting (minimize error using gradients)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Ensembling Techniques\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Decision Trees\n",
    "\n",
    "### Basic Algorithm\n",
    "\n",
    "1. Check for the above base cases.\n",
    "2. For each feature $f_i$, find the **metric** from splitting on the criteria $c$ based on $f_i$, e.g. if $f_i > 4.3$ (Regression) or if $f_i == \\text{Dog}$ (Classification).\n",
    "3. Let $c_{best}$ be the \"best\" criteria with the \"best\" metric result.\n",
    "4. Create a decision node that splits on $c_{best}$.\n",
    "5. Recur on the sublists obtained by splitting on $c_{best}$, and add those nodes as children of node.\n",
    "\n",
    "There are multiple variations on this basic decision tree algorithm and most of them work the same way by choosing the best criteria for splitting and recursively splitting until all the overall metrics are the best, but we can categorize them based on the **metrics** they use to decide how to split a node.\n",
    "\n",
    "## Metrics\n",
    "\n",
    "Gini Impurity:\n",
    "- Used by CART's (Classification And Regression Trees) Classification Trees\n",
    "\n",
    "Variance Reduction:\n",
    "- Used by CART's (Classification And Regression Trees) Regression Trees\n",
    "\n",
    "Information Gain: $\\overbrace{IG(T, criteria)}^\\text{Information Gain} \n",
    "= \\overbrace{(T)}^\\text{Entropy (parent)} \n",
    "- \\overbrace{(T\\vert criteria)}^\\text{Weighted Sum of Entropy (Children)} =-\\sum_{i=1}^{J}p_i\\log_2{p_i} - \\sum_{a}{p(a)\\sum_{i=1}^{J}-\\Pr(i\\vert a)\\log_2{\\Pr(i\\vert a)}}$\n",
    "- Used by ID3, C4.5 (successor of ID3), and C5.0 (successor of C4.5), can be used for both classification and regression\n",
    "\n",
    "## Problems\n",
    "Overfitting\n",
    "- Solutions:\n",
    "    - Post pruning using Chi Squared Test\n",
    "    - max depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Resources:\n",
    "\n",
    "- [Tips for stacking and blending](https://www.kaggle.com/zaochenye/tips-for-stacking-and-blending)\n",
    "- [Stacking Classifer](https://www.youtube.com/watch?v=sBrQnqwMpvA)\n",
    "- [Victor Lavrenko on Decision Trees](https://www.youtube.com/watch?v=eKD5gxPPeY0&list=PLBv09BD7ez_4temBw7vLA19p3tdQH6FYO)\n",
    "- [Statquest on Decision Trees](https://www.youtube.com/watch?v=7VeUPuFGJHk)\n",
    "- [Basic Decision Tree algorithm Wiki](https://en.wikipedia.org/wiki/C4.5_algorithm#pseudocode)\n",
    "- [Decision Tree Splitting Metrics Wiki](https://en.wikipedia.org/wiki/Decision_tree_learning#Metrics)\n",
    "- [Rishabh Jain on Decision Trees](https://medium.com/@rishabhjain_22692/decision-trees-it-begins-here-93ff54ef134)\n",
    "- [CMU ML Decision Trees Notes](http://alex.smola.org/teaching/cmu2013-10-701/slides/23_Trees.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
