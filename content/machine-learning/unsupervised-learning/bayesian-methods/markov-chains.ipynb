{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chains\n",
    "\n",
    "A Markov Chain is a discrete stochastic process with the *Markov property* : $P(X_t \\mid X_{t−1}, \\ldots,X_1)=P(X_t \\mid X_{t−1})$. It is fully determined by a probability transition matrix $P$ which defines the transition probabilities $(P_{ij}=P(X_t=j \\mid X_{t−1}=i)$ and an initial probability distribution specified by the vector $x$ where $x_i=P(X_0=i)$. The time-dependent random variable $X_t$ is describing the state of our probabilistic system at time-step $t$.\n",
    "\n",
    "We'll go through markov chains using this example:\n",
    "- Consider a world where a company A has 10% of the market share, meaning that other pest extermination companies have 90% of the market share. A is considering launching an ad campaign which they predict will have the following result:\n",
    "    - People using other brands will **switch** to A with a probability of 0.6 within **one week** after seeing the ad\n",
    "    - People already using A will **continue** using A with a probability of 0.8 within **one week** after seeing the ad\n",
    "- Now we will use a Markov chain to model this process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Initial State Distribution Matrix\n",
    "\n",
    "$$\n",
    "S_0 = \n",
    "\\stackrel{\\mbox{$A\\,\\,\\,\\,\\,\\neg A$}}\n",
    "{\\underset{1\\,\\times\\,2}\n",
    "{\\begin{bmatrix}\n",
    "  0.1 & 0.9 \\\\\n",
    "\\end{bmatrix}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.9])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_0 = np.array([0.1, 0.9])\n",
    "S_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Transition Probability Matrix\n",
    "\n",
    "$$\n",
    "P =\n",
    "\\text{Current State}\\,\n",
    "\\begin{cases}\n",
    "A \\\\\n",
    "\\neg A \\\\\n",
    "\\end{cases}\n",
    "\\overbrace{\n",
    "\\stackrel{\\mbox{$A\\,\\,\\,\\,\\,\\neg A$}}\n",
    "{\n",
    "\\underset{2\\,\\times\\,2}{\n",
    "\\begin{bmatrix}\n",
    "  0.8 & 0.2 \\\\\n",
    "  0.6 & 0.4 \\\\\n",
    "\\end{bmatrix}}}\n",
    "}^{\\text{Next State}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8, 0.2],\n",
       "       [0.6, 0.4]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = np.array([[0.8, 0.2], [0.6, 0.4]])\n",
    "P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# After $1$ weeks...\n",
    "\n",
    "After 1 week:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "S_1 &= S_0 \\cdot P^1 \\\\\n",
    "&= \\underset{1\\,\\times\\,2}{\\begin{bmatrix} 0.1 & 0.9 \\\\ \\end{bmatrix}}\n",
    "\\cdot \\underset{2\\,\\times\\,2}{\\begin{bmatrix} 0.8 & 0.2 \\\\ 0.6 & 0.4 \\\\ \\end{bmatrix}} \\\\\n",
    "&= \\underset{1\\,\\times\\,2}{\\begin{bmatrix} 0.62 & 0.38 \\\\ \\end{bmatrix}}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62, 0.38])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_1 = np.dot(S_0, P)\n",
    "S_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# After $2$ weeks...\n",
    "\n",
    "After 1 week:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "S_1 &= S_0 \\cdot P^2 \\\\\n",
    "&= \\underset{1\\,\\times\\,2}{\\begin{bmatrix} 0.1 & 0.9 \\\\ \\end{bmatrix}}\n",
    "\\cdot \\underset{2\\,\\times\\,2}{\\begin{bmatrix} 0.8 & 0.2 \\\\ 0.6 & 0.4 \\\\ \\end{bmatrix}} \\cdot \\underset{2\\,\\times\\,2}{\\begin{bmatrix} 0.8 & 0.2 \\\\ 0.6 & 0.4 \\\\ \\end{bmatrix}} \\\\\n",
    "&= \\underset{1\\,\\times\\,2}{\\begin{bmatrix} 0.724 & 0.276 \\\\ \\end{bmatrix}}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.724, 0.276])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_2 = np.dot(np.dot(S_0, P), P)\n",
    "S_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Stationary Matrix\n",
    "\n",
    "If the probabilities in $P$ remain valid over a long period of time, what happens to the companies market share?\n",
    "\n",
    "After $n$ weeks:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "S_n &= S_0 \\cdot P^n \\\\\n",
    "&= \\underset{1\\,\\times\\,2}{\\begin{bmatrix} 0.1 & 0.9 \\\\ \\end{bmatrix}}\n",
    "\\cdot \\underset{2\\,\\times\\,2}{\n",
    "{\\begin{bmatrix} 0.8 & 0.2 \\\\ 0.6 & 0.4 \\\\ \\end{bmatrix}}^n\n",
    "} \\\\\n",
    "&= \\underset{1\\,\\times\\,2}{\\begin{bmatrix} 0.75 & 0.25 \\\\ \\end{bmatrix}}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75, 0.25])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 100\n",
    "S_n = np.dot(S_0, np.linalg.matrix_power(P, n))\n",
    "S_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix $S_n$ is known as the Stationary matrix, and the system is said to be at steady state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.75, 0.25],\n",
       "       [0.75, 0.25]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.matrix_power(P, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that after a large number of steps the initial state does not matter any more, the probability of the chain being in any state $j$ is independent of where we started. This is our first view of the *equilibrium distribuion* of a Markov Chain. These are also known as the *limiting probabilities* of a Markov chain or *stationary distribution*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Questions\n",
    "\n",
    "- Does every Markov Chain have a unique stationary matrix?\n",
    "    - No, only for **regular** markov chains\n",
    "\n",
    "- If a Markov chain has a unique stationary matrix, will the successive state matrices always approach this stationary matrix?\n",
    "    - No, only for **regular** markov chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Regular Markov Chains\n",
    "\n",
    "- A transition matrix $P$ is regular if some power of $P$ has only positive entries. A markov chain is a regular markov chain if its transition matrix is regular.\n",
    "    - i.e. If you keep multiplying $P$ by itself and at some point you get all positive entries, then the matrix is regular\n",
    "    \n",
    "## Properties\n",
    "\n",
    "Let $P$ be the transition matrix for a regular markov chain\n",
    "1. There is a unique stationary matrix $\\pi$ that can be found by solving the equation $\\pi \\cdot P = \\pi$\n",
    "- Given any initial state matrix $\\pi_0$, the state matrices $\\pi_k$ approach the stationary matrix $\\pi$\n",
    "- The matrices $P^k$ approach a limiting matrix $\\bar{P}$, where each row of $\\bar{P}$ is equal to the stationary matrix $\\pi$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. $\\pi \\cdot P = \\pi$\n",
    "\n",
    "E.g.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\pi \\cdot P &= \\pi \\\\\n",
    "{\\begin{bmatrix} s_1 & s_2 \\end{bmatrix}} \\cdot \n",
    "{\\begin{bmatrix} 0.6 & 0.4 \\\\ 0.2 & 0.8 \\end{bmatrix}}\n",
    "&= {\\begin{bmatrix} s_1 & s_2 \\end{bmatrix}} \\\\\n",
    "\\vdots \\\\\n",
    "0.6s_1 + 0.2s_2 &= s_1 \\\\\n",
    "0.4s_1 + 0.8s_2 &= s_2 \\\\\n",
    "s_1 + s_2 &= 1 \\\\\n",
    "\\vdots \\\\\n",
    "s_1 &\\approx 0.33 \\\\\n",
    "s_2 &\\approx 0.67 \\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice again that the initial state matrix doesn't matter at all unless your markov chain isn't regular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Absorbing Markov Chains\n",
    "\n",
    "- A state in a markov chain is called an **absorbing state** if once the state is entered, it is impossible to leave.\n",
    "    - i.e. entries on the diagonal, $p_{ii} = 1$, state i is an absorbing state\n",
    "\n",
    "- A markov chain is an absorbing chain if:\n",
    "    1. There is at least one absorbing state\n",
    "    2. It is possible to go from each non-absorbing state to at least one absorbing state in a finite number of steps\n",
    "        - There should be a set of arrows in a transition diagram from each node to an absorbing node\n",
    "        \n",
    "## Standard Form\n",
    "\n",
    "- All absorbing states (will form an identity matrix) precede the non-absorbing states in the matrix\n",
    "\n",
    "$$\n",
    "P = \n",
    "\\begin{aligned}\n",
    "&A \\\\\n",
    "&B \\\\\n",
    "&C \\\\\n",
    "&D \\\\\n",
    "\\end{aligned}\n",
    "\\stackrel{\\mbox{$A\\,\\,\\,\\,\\,\\,\\,\\,\\,B\\,\\,\\,\\,\\,\\,\\,\\,\\,C\\,\\,\\,\\,\\,\\,\\,\\,\\,D$}}\n",
    "{\n",
    "\\begin{bmatrix}\n",
    "    0.0 & 0.3 & 0.3 & 0.4 \\\\\n",
    "    0.0 & 1.0 & 0.0 & 0.0 \\\\\n",
    "    0.0 & 0.0 & 1.0 & 0.0 \\\\\n",
    "    0.8 & 0.1 & 0.1 & 0.0 \\\\\n",
    "\\end{bmatrix}\n",
    "}\n",
    "\\,\n",
    "\\underset{\\text{Standardize}}{\\rightarrow}\n",
    "\\,\n",
    "\\begin{aligned}\n",
    "&B \\\\\n",
    "&C \\\\\n",
    "&A \\\\\n",
    "&D \\\\\n",
    "\\end{aligned}\n",
    "\\stackrel{\\mbox{$B\\,\\,\\,\\,\\,\\,\\,\\,\\,C\\,\\,\\,\\,\\,\\,\\,\\,\\,A\\,\\,\\,\\,\\,\\,\\,\\,\\,D$}}\n",
    "{\n",
    "\\begin{bmatrix}\n",
    "    1.0 & 0.0 & 0.0 & 0.0 \\\\\n",
    "    0.0 & 1.0 & 0.0 & 0.0 \\\\\n",
    "    0.3 & 0.3 & 0.0 & 0.4 \\\\\n",
    "    0.1 & 0.1 & 0.8 & 0.0 \\\\\n",
    "\\end{bmatrix}\n",
    "}\n",
    "$$\n",
    "\n",
    "$$\n",
    "I =\n",
    "\\begin{bmatrix}\n",
    "    1.0 & 0.0 \\\\\n",
    "    0.0 & 1.0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "O =\n",
    "\\begin{bmatrix}\n",
    "    0.0 & 0.0 \\\\\n",
    "    0.0 & 0.0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "R =\n",
    "\\begin{bmatrix}\n",
    "    0.3 & 0.3 \\\\\n",
    "    0.1 & 0.1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "Q =\n",
    "\\begin{bmatrix}\n",
    "    0.0 & 0.4 \\\\\n",
    "    0.8 & 0.0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "If a standard form $P$ for an absorbing markov chain is partitioned as:\n",
    "$$\n",
    "P = \n",
    "\\begin{bmatrix}\n",
    "    I & O \\\\\n",
    "    R & Q\n",
    "\\end{bmatrix} \n",
    "\\,\n",
    "\\text{Standard Form},\n",
    "$$\n",
    "then $P^k$ approaches a limiting matrix $\\bar{P}$ as $k$ increases, where\n",
    "$$\n",
    "\\bar{P} =\n",
    "\\begin{bmatrix}\n",
    "    I  & O \\\\\n",
    "    FR & O\n",
    "\\end{bmatrix} \n",
    "\\,\n",
    "\\text{and}\n",
    "\\,\n",
    "F = {(I - Q)}^{-1},\n",
    "\\,\n",
    "F\\text{: Fundamental Matrix for }\\,P\n",
    "\\,\n",
    "$$\n",
    "\n",
    "i.e. In the long run, $\\bar{P}$:\n",
    "$$\n",
    "\\bar{P} =\n",
    "\\begin{bmatrix}\n",
    "    I  & O \\\\\n",
    "    FR & O\n",
    "\\end{bmatrix} \n",
    "=\n",
    "\\begin{bmatrix}\n",
    "    B \\rightarrow B=1.0 & B \\rightarrow C=0.0 & B \\rightarrow A=0.0 & B \\rightarrow D=0.0 \\\\\n",
    "    C \\rightarrow B=0.0 & C \\rightarrow C=1.0 & C \\rightarrow A=0.0 & C \\rightarrow D=0.0 \\\\\n",
    "    A \\rightarrow B=0.5 & A \\rightarrow C=0.5 & A \\rightarrow A=0.0 & A \\rightarrow D=0.0 \\\\\n",
    "    D \\rightarrow B=0.5 & D \\rightarrow C=0.5 & D \\rightarrow A=0.0 & D \\rightarrow D=0.0 \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.array([[1.0, 0.0, 0.0, 0.0],\n",
    "              [0.0, 1.0, 0.0, 0.0], \n",
    "              [0.3, 0.3, 0.0, 0.4], \n",
    "              [0.1, 0.1, 0.8, 0.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I = P[:2,:2]\n",
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O = P[:2,2:]\n",
    "O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3, 0.3],\n",
       "       [0.1, 0.1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = P[2:,:2]\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0.4],\n",
       "       [0.8, 0. ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = P[2:,2:]\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.47058824, 0.58823529],\n",
       "       [1.17647059, 1.47058824]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F = np.linalg.inv(I - Q)\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 0. , 0. , 0. ],\n",
       "       [0. , 1. , 0. , 0. ],\n",
       "       [0.5, 0.5, 0. , 0. ],\n",
       "       [0.5, 0.5, 0. , 0. ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_bar = np.concatenate((np.concatenate((I, O), axis=1), \n",
    "                        np.concatenate((np.dot(F, R), O), axis=1)), axis=0)\n",
    "P_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Ergodic Markov Chains\n",
    "\n",
    "- Not every Markov Chain has a stationary distribution or even a unique one. But we can guarantee these properties if we add two additional constraints to the Markov Chain:\n",
    "    1. ***Irreducible***: we must be able to reach any one state from any other state eventually (i.e. the expected number of steps is finite).\n",
    "    2. ***Aperiodic***: the system never returns to the same state with a fixed period (e.g. not returning to start \"sunny\" deterministically every 5 steps).\n",
    "    \n",
    "- Together these two properties define the property ergodic. An important theorem says that if a Markov Chain is ergodic then it has a unique steady state probability vector $\\pi$. In the context of MCMC, we can jump from any state to any other state (with some finite probability), trivially satisfying irreducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Detailed balance and Reversible Markov Chains\n",
    "\n",
    "- A Markov Chain is said to be reversible (also known as the detailed balance condition) if there exists a probability distribution $\\pi$ that satisfies this condition:\n",
    "\n",
    "$$ \\pi_i P(X_{n+1}=j \\mid X_n=i)=\\pi_j P(X_{n+1}=i\\mid X_n=j) (3)$$\n",
    "\n",
    "- In other words, in the long run, the proportion of times that you transition from state $i$ to state $j$ is the same as the proportion of times you transition from state $j$ to state $i$. In fact, if a Markov Chain is reversible then we know that it has a stationary distribution (which is why we use the same notation $\\pi$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Resources:\n",
    "- [patrickJMT on Markov Chains](https://www.youtube.com/watch?v=uvYTGEZQTEs)\n",
    "- [Matthew Stephens on Markov Chains](https://stephens999.github.io/fiveMinuteStats/markov_chains_discrete_intro.html)\n",
    "- [Brian Keng on MCMC](http://bjlkeng.github.io/posts/markov-chain-monte-carlo-mcmc-and-the-metropolis-hastings-algorithm/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
