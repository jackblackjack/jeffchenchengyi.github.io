---
interact_link: content/machine-learning/dimensionality-reduction/main-dimensionality-reduction-technqiues.ipynb
kernel_name: python3
has_widgets: false
title: 'Dimensionality Reduction'
prev_page:
  url: /machine-learning/neural-networks/cnn
  title: 'Convolutional Neural Networks'
next_page:
  url: /machine-learning/natural-language-processing/what-is-natural-language-processing
  title: 'Natural Language Processing'
comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---


# Dimensionality Reduction

We will go over a few of the main dimensionality reduction techniques in the machine learning space.



---
# Principal Component Analysis





---
# Linear Discriminant Analysis



---
# Factor Analysis



---
# Canonical Correlation Analysis



---
# TSNE (T-distributed Stochastic Neighbourhood Embeddings)



---
## Resources:
- [Penn State's STAT505 Lesson Notes](https://newonlinecourses.science.psu.edu/stat505/)
- [Stat Quest's "StatQuest: Principal Component Analysis (PCA), Step-by-Step"](https://www.youtube.com/watch?v=FgakZw6K1QQ&t=16s)
- [Very intuitive and detailed explanation of PCA](https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues)

