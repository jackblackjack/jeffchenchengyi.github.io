---
interact_link: content/machine-learning/supervised-learning/ensemble/ensemble.ipynb
kernel_name: python3
has_widgets: false
title: 'Ensembles'
prev_page:
  url: /machine-learning/supervised-learning/regression/regression
  title: 'Regression'
next_page:
  url: /machine-learning/supervised-learning/time-series-analysis/time-series-models
  title: 'Time Series Analysis'
comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---


# Ensembling with Trees

We will go through an overview of the different types of tree-based algorithms in the literature and how they work using ensembling techniques like bagging (boostrapping + aggregating) and boosting (minimize error using gradients).



---
# Ensembling Techniques





## Bagging



## Boosting



## Stacking



---
# Decision Trees



---
# Random Forest



---
# AdaBoost



---
# Gradient Boosted Trees



---
# XGBoost



---
## Resources:

- [Tips for stacking and blending](https://www.kaggle.com/zaochenye/tips-for-stacking-and-blending)
- [Stacking Classifer](https://www.youtube.com/watch?v=sBrQnqwMpvA)

